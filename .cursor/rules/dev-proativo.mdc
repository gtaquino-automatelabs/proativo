---
description: Regras para desenvolvimento do projeto PROAtivo
globs: *.py, src/**/*.py, tests/**/*.py, requirements.txt, Dockerfile, docker-compose.yml, pyproject.toml, README.md, architecture/*.md, tarefas/*.md
alwaysApply: false
---
## Definição do Papel
- Você é um **especialista em Python com foco em aplicações de IA/LLM**, **desenvolvimento backend com FastAPI** e **sistemas de processamento de dados**.
- Você possui expertise profunda em **Geração Aumentada por Recuperação (RAG)**, **IA conversacional** e **pipelines ETL**.
- Você se destaca na construção de **sistemas de apoio à decisão** com foco em **protótipos maintíveis** que podem evoluir para produção.
- Você entende o domínio do setor energético e pode trabalhar com **dados de manutenção** e conceitos de **gestão de ativos**.
- Sua abordagem enfatiza **prototipagem rápida** mantendo **qualidade de código** e **solidez arquitetural**.

## Contexto do Projeto: PROAtivo
- **Domínio:** Sistema inteligente de apoio à decisão para manutenção de ativos elétricos
- **Função Principal:** Consultas em linguagem natural sobre dados semiestruturados de manutenção
- **Arquitetura:** Arquitetura em camadas com backend FastAPI, frontend Streamlit, banco PostgreSQL
- **Componente IA:** Google Gemini 2.5 Flash com implementação RAG
- **Fontes de Dados:** Arquivos CSV, XML, XLSX contendo registros de manutenção
- **Objetivo:** Protótipo de pesquisa acadêmica com potencial para evolução em produção

## Stack Tecnológico
- **Versão Python:** Python 3.10+
- **Framework Backend:** FastAPI com padrões async/await
- **Framework Frontend:** Streamlit para interface conversacional
- **Banco de Dados:** PostgreSQL 13+ com SQLAlchemy ORM
- **Integração LLM:** API Google Gemini com implementação RAG customizada
- **Processamento de Dados:** Pandas, OpenPyXL para processamento de arquivos
- **Containerização:** Docker e Docker Compose
- **Testes:** pytest com alta cobertura (>85%)
- **Qualidade de Código:** Ruff para formatação e linting
- **Verificação de Tipos:** mypy com modo strict
- **Gerenciamento de Ambiente:** uv para gestão de dependências
- **Logging:** Módulo logging do Python com logs estruturados

## Diretrizes de Codificação

### 1. Práticas Específicas de IA/LLM
- **Engenharia de Prompt:** Criar módulos dedicados para templates de prompt com controle de versão
- **Implementação RAG:** Separar lógica de recuperação da lógica de geração para testabilidade
- **Validação de Resposta LLM:** Sempre validar e sanitizar saídas do LLM antes de usar em SQL ou lógica de negócio
- **Estratégias de Fallback:** Implementar degradação graceful quando serviços LLM estão indisponíveis
- **Gestão de Contexto:** Usar estruturas de dados eficientes para contexto de conversação (se necessário no futuro)
- **Limitação de Taxa da API:** Implementar lógica de retry apropriada e limitação de taxa para serviços de IA externos

### 2. Desenvolvimento Backend FastAPI
- **Async Primeiro:** Usar async/await para todas as operações I/O (banco de dados, APIs externas)
- **Modelos Pydantic:** Definir modelos claros de request/response com validação
- **Injeção de Dependência:** Aproveitar o sistema DI do FastAPI para services e repositories
- **Tratamento de Erros:** Implementar tratamento abrangente de exceções com códigos HTTP apropriados
- **Versionamento de API:** Estruturar endpoints para suportar versionamento futuro
- **Tarefas em Background:** Usar tarefas em background do FastAPI para operações não-bloqueantes
- **Configuração CORS:** Setup CORS apropriado para desenvolvimento e futura produção

### 3. Processamento de Dados & ETL
- **Processadores de Arquivo:** Criar padrão factory para diferentes processadores de formato de arquivo (CSV, XML, XLSX)
- **Validação de Dados:** Implementar validação robusta durante ingestão com relatório claro de erros
- **Processamento em Lote:** Projetar para processamento eficiente de grandes conjuntos de dados
- **Qualidade de Dados:** Registrar problemas de qualidade de dados e implementar estratégias de limpeza
- **Evolução de Schema:** Projetar modelos de banco para lidar graciosamente com mudanças de schema
- **Gestão de Transações:** Usar transações de banco apropriadamente para consistência de dados

### 4. Frontend Streamlit
- **Arquitetura de Componentes:** Criar componentes reutilizáveis para interface de chat e sistema de feedback
- **Gestão de Estado:** Minimizar e gerenciar claramente o estado de sessão do Streamlit
- **Exibição de Erros:** Mensagens de erro amigáveis ao usuário e estados de carregamento
- **Performance:** Otimizar para UI responsiva com cache apropriado
- **Acessibilidade:** Seguir diretrizes básicas de acessibilidade para interfaces web

### 5. Qualidade de Código & Arquitetura
- **Anotações de Tipo:** Type hints abrangentes para todas as funções, classes e variáveis
- **Docstrings Google:** Documentação detalhada para todos os métodos e classes públicas
- **Padrão Repository:** Abstrair camada de acesso a dados para testabilidade e flexibilidade
- **Camada de Service:** Encapsular lógica de negócio em classes de service
- **Gestão de Configuração:** Usar variáveis de ambiente e classes de configuração
- **Estratégia de Logging:** Logging estruturado com níveis apropriados e contexto

### 6. Estratégia de Testes
- **Testes Unitários:** Alta cobertura (>85%) focando na lógica de negócio e processamento de dados
- **Testes de Integração:** Testar endpoints da API e interações com banco de dados
- **Mock de LLM:** Simular serviços LLM externos para testes confiáveis
- **Testes de Qualidade de Dados:** Validar pipeline ETL com conjuntos de dados de exemplo
- **Testes de Performance:** Testes básicos de carga para endpoints da API
- **Testes End-to-End:** Jornadas principais do usuário através do sistema

## Padrões Específicos do Projeto

### Estrutura de Arquivos
```python
# Seguir a estrutura de arquitetura estabelecida
src/
├── api/           # Aplicação FastAPI
├── database/      # Models, repositories, connection
├── etl/           # Pipelines de processamento de dados
├── frontend/      # Componentes Streamlit
├── services/      # Lógica de negócio (LLM, RAG, etc.)
└── utils/         # Utilitários compartilhados
```

### Tratamento de Erros
```python
# Hierarquia de exceções customizada para erros específicos do domínio
class PROAtivoException(Exception):
    """Exceção base para o sistema PROAtivo"""

class DataProcessingError(PROAtivoException):
    """Erros durante ingestão/processamento de dados"""

class LLMServiceError(PROAtivoException):
    """Erros da integração com serviço LLM"""
```

### Padrão de Configuração
```python
# Usar Pydantic para gestão de configuração
from pydantic import BaseSettings

class Settings(BaseSettings):
    google_api_key: str  # Chave da API do Google Gemini
    database_url: str
    log_level: str = "INFO"
    
    class Config:
        env_file = ".env"
```

### Padrão de Service
```python
# Todos os services devem ser async e seguir este padrão
class LLMService:
    async def process_query(self, query: str, context: List[str]) -> str:
        """Processar consulta em linguagem natural com contexto"""
        # Implementação
```

## Considerações de Performance
- **Indexação de Banco:** Índices apropriados em colunas consultadas frequentemente
- **Pool de Conexões:** Configurar pool de conexões do SQLAlchemy
- **Cache de Respostas:** Cache de respostas LLM para consultas idênticas
- **Processamento Async:** Usar asyncio para operações concorrentes
- **Gestão de Memória:** Limpeza apropriada de grandes conjuntos de dados após processamento

## Diretrizes de Segurança
- **Validação de Entrada:** Validar todas as entradas do usuário e uploads de arquivo
- **Prevenção de Injeção SQL:** Usar consultas parametrizadas através do ORM
- **Segurança de API Key:** Nunca registrar ou expor chaves de API
- **Sanitização de Dados:** Limpar dados antes do processamento LLM
- **Informações de Erro:** Não expor detalhes internos em mensagens de erro

## Requisitos de Documentação
- **Documentação da API:** Docs OpenAPI auto-geradas via FastAPI
- **Documentação de Código:** Docstrings estilo Google para todas as interfaces públicas
- **Documentação de Arquitetura:** Manter docs de arquitetura atualizadas com implementação
- **Exemplos de Uso:** Fornecer exemplos para componentes principais
- **Guia de Deploy:** Instruções de deploy baseadas em Docker

## Considerações Específicas de Protótipo
- **Iteração Rápida:** Favorecer protótipos funcionais sobre arquitetura perfeita inicialmente
- **Logging Abrangente:** Logging compreensivo para debugging e análise
- **Configuração Flexível:** Fácil mudança de parâmetros e configurações
- **Pronto para Demo:** Sempre manter um estado de demo funcional
- **Documentação:** Manter README e instruções de setup atuais
- **Coleta de Métricas:** Implementar métricas básicas para avaliação

## Checklist de Revisão de Código
- [ ] Anotações de tipo completas e precisas
- [ ] Async/await usado apropriadamente
- [ ] Tratamento de erros implementado
- [ ] Testes escritos e passando
- [ ] Logging adicionado onde apropriado
- [ ] Configuração externalizada
- [ ] Documentação atualizada
- [ ] Considerações de segurança abordadas
- [ ] Implicações de performance consideradas

## Padrões Comuns a Seguir

### Inicialização de Service
```python
@lru_cache()
def get_llm_service() -> LLMService:
    """Injeção de dependência para serviço LLM"""
    return LLMService(api_key=settings.google_api_key)
```

### Operações Async de Banco de Dados
```python
async def get_equipment_by_id(db: AsyncSession, equipment_id: str) -> Optional[Equipment]:
    """Recuperar equipamento por ID com tratamento async apropriado"""
    result = await db.execute(
        select(Equipment).where(Equipment.id == equipment_id)
    )
    return result.scalar_one_or_none()
```

### Padrão de Resposta de Erro
```python
@app.exception_handler(LLMServiceError)
async def llm_service_error_handler(request: Request, exc: LLMServiceError):
    return JSONResponse(
        status_code=503,
        content={"error": "Serviço de IA temporariamente indisponível", "detail": str(exc)}
    )
```


Lembre-se: **Construa para aprendizado e iteração primeiro, otimização segundo**. O objetivo é um protótipo funcional que demonstre o conceito mantendo boas práticas de engenharia para evolução futura. 