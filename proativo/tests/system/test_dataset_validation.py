#!/usr/bin/env python3
"""
Script simplificado para validar o dataset de queries de teste do PROAtivo.
Valida a estrutura JSON e fornece estatÃ­sticas do dataset.
"""

import json
import sys
from pathlib import Path
from typing import Dict, Any
from datetime import datetime

class DatasetValidator:
    """Validador do dataset de queries"""
    
    def __init__(self):
        self.dataset_path = Path(__file__).parent.parent / "data" / "test_dataset" / "query_test_dataset.json"
        
    def load_dataset(self) -> Dict[str, Any]:
        """Carrega e valida o dataset de queries"""
        try:
            with open(self.dataset_path, 'r', encoding='utf-8') as f:
                dataset = json.load(f)
            return dataset
        except FileNotFoundError:
            raise FileNotFoundError(f"Dataset nÃ£o encontrado: {self.dataset_path}")
        except json.JSONDecodeError as e:
            raise ValueError(f"Erro ao decodificar JSON: {e}")
    
    def validate_structure(self, dataset: Dict[str, Any]) -> Dict[str, Any]:
        """Valida a estrutura do dataset"""
        validation_result = {
            'valid': True,
            'errors': [],
            'warnings': []
        }
        
        # Verificar metadados
        if 'metadata' not in dataset:
            validation_result['errors'].append("Campo 'metadata' ausente")
        else:
            metadata = dataset['metadata']
            required_meta_fields = ['name', 'version', 'total_queries', 'categories']
            for field in required_meta_fields:
                if field not in metadata:
                    validation_result['errors'].append(f"Campo 'metadata.{field}' ausente")
        
        # Verificar queries
        if 'queries' not in dataset:
            validation_result['errors'].append("Campo 'queries' ausente")
        else:
            queries = dataset['queries']
            if not isinstance(queries, list):
                validation_result['errors'].append("Campo 'queries' deve ser uma lista")
            else:
                # Validar cada query
                required_query_fields = ['id', 'query', 'category', 'complexity', 'expected_route']
                for i, query in enumerate(queries):
                    for field in required_query_fields:
                        if field not in query:
                            validation_result['errors'].append(f"Query {i}: Campo '{field}' ausente")
                    
                    # Verificar IDs Ãºnicos
                    query_ids = [q.get('id') for q in queries]
                    if len(query_ids) != len(set(query_ids)):
                        validation_result['errors'].append("IDs de queries nÃ£o sÃ£o Ãºnicos")
        
        # Verificar estatÃ­sticas
        if 'statistics' not in dataset:
            validation_result['warnings'].append("Campo 'statistics' ausente")
        
        validation_result['valid'] = len(validation_result['errors']) == 0
        return validation_result
    
    def analyze_dataset(self, dataset: Dict[str, Any]) -> Dict[str, Any]:
        """Analisa o conteÃºdo do dataset"""
        queries = dataset.get('queries', [])
        
        analysis = {
            'total_queries': len(queries),
            'categories': {},
            'complexity_levels': {},
            'expected_routes': {},
            'priorities': {},
            'domain_coverage': {}
        }
        
        # AnÃ¡lise detalhada
        for query in queries:
            # Por categoria
            cat = query.get('category', 'unknown')
            analysis['categories'][cat] = analysis['categories'].get(cat, 0) + 1
            
            # Por complexidade
            comp = query.get('complexity', 'unknown')
            analysis['complexity_levels'][comp] = analysis['complexity_levels'].get(comp, 0) + 1
            
            # Por rota esperada
            route = query.get('expected_route', 'unknown')
            analysis['expected_routes'][route] = analysis['expected_routes'].get(route, 0) + 1
            
            # Por prioridade
            priority = query.get('test_priority', 'unknown')
            analysis['priorities'][priority] = analysis['priorities'].get(priority, 0) + 1
            
            # Cobertura de domÃ­nio (palavras-chave)
            keywords = query.get('domain_keywords', [])
            for keyword in keywords:
                analysis['domain_coverage'][keyword] = analysis['domain_coverage'].get(keyword, 0) + 1
        
        return analysis
    
    def generate_report(self, dataset: Dict[str, Any], validation: Dict[str, Any], analysis: Dict[str, Any]) -> str:
        """Gera relatÃ³rio completo do dataset"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ“Š RELATÃ“RIO DE VALIDAÃ‡ÃƒO DO DATASET DE QUERIES")
        report.append("=" * 80)
        report.append(f"ğŸ“… Data de validaÃ§Ã£o: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ğŸ“ Arquivo: {self.dataset_path}")
        report.append("")
        
        # Status de validaÃ§Ã£o
        if validation['valid']:
            report.append("âœ… VALIDAÃ‡ÃƒO: APROVADO")
        else:
            report.append("âŒ VALIDAÃ‡ÃƒO: REPROVADO")
        
        if validation['errors']:
            report.append(f"\nâŒ Erros encontrados ({len(validation['errors'])}):")
            for error in validation['errors']:
                report.append(f"   â€¢ {error}")
        
        if validation['warnings']:
            report.append(f"\nâš ï¸  Avisos ({len(validation['warnings'])}):")
            for warning in validation['warnings']:
                report.append(f"   â€¢ {warning}")
        
        # EstatÃ­sticas do dataset
        report.append(f"\nğŸ“ˆ ESTATÃSTICAS DO DATASET")
        report.append(f"ğŸ”¢ Total de queries: {analysis['total_queries']}")
        
        report.append(f"\nğŸ“Š DistribuiÃ§Ã£o por Categoria:")
        for cat, count in sorted(analysis['categories'].items()):
            percentage = (count / analysis['total_queries']) * 100
            report.append(f"   {cat}: {count} queries ({percentage:.1f}%)")
        
        report.append(f"\nğŸ¯ DistribuiÃ§Ã£o por Complexidade:")
        for comp, count in sorted(analysis['complexity_levels'].items()):
            percentage = (count / analysis['total_queries']) * 100
            report.append(f"   {comp}: {count} queries ({percentage:.1f}%)")
        
        report.append(f"\nğŸ”„ DistribuiÃ§Ã£o por Rota Esperada:")
        for route, count in sorted(analysis['expected_routes'].items()):
            percentage = (count / analysis['total_queries']) * 100
            report.append(f"   {route}: {count} queries ({percentage:.1f}%)")
        
        report.append(f"\nğŸ¯ DistribuiÃ§Ã£o por Prioridade de Teste:")
        for priority, count in sorted(analysis['priorities'].items()):
            percentage = (count / analysis['total_queries']) * 100
            report.append(f"   {priority}: {count} queries ({percentage:.1f}%)")
        
        # Top 10 palavras-chave mais comuns
        if analysis['domain_coverage']:
            top_keywords = sorted(analysis['domain_coverage'].items(), key=lambda x: x[1], reverse=True)[:10]
            report.append(f"\nğŸ”‘ Top 10 Palavras-chave do DomÃ­nio:")
            for keyword, count in top_keywords:
                report.append(f"   {keyword}: {count} ocorrÃªncias")
        
        # Amostras por categoria
        queries = dataset.get('queries', [])
        report.append(f"\nğŸ“‹ AMOSTRAS DE QUERIES POR CATEGORIA:")
        for category in sorted(analysis['categories'].keys()):
            category_queries = [q for q in queries if q.get('category') == category][:2]  # Primeiras 2
            report.append(f"\n   ğŸ“‚ {category.upper()}:")
            for query in category_queries:
                query_text = query.get('query', '')
                if len(query_text) > 60:
                    query_text = query_text[:60] + "..."
                report.append(f"     â€¢ {query.get('id')}: {query_text}")
                report.append(f"       Complexidade: {query.get('complexity')} | Rota: {query.get('expected_route')}")
        
        report.append("\n" + "=" * 80)
        return "\n".join(report)

def main():
    """FunÃ§Ã£o principal"""
    validator = DatasetValidator()
    
    try:
        print("ğŸ” Carregando dataset...")
        dataset = validator.load_dataset()
        
        print("âœ… Dataset carregado com sucesso!")
        print(f"ğŸ“Š Total de queries: {len(dataset.get('queries', []))}")
        
        print("\nğŸ” Validando estrutura...")
        validation = validator.validate_structure(dataset)
        
        print("ğŸ“ˆ Analisando conteÃºdo...")
        analysis = validator.analyze_dataset(dataset)
        
        print("ğŸ“‹ Gerando relatÃ³rio...")
        report = validator.generate_report(dataset, validation, analysis)
        
        print(report)
        
        # Salvar relatÃ³rio em arquivo
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"dataset_validation_report_{timestamp}.txt"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ’¾ RelatÃ³rio salvo em: {report_filename}")
        
        # Status de saÃ­da
        if not validation['valid']:
            print("\nâŒ ValidaÃ§Ã£o falhou. Verifique os erros acima.")
            sys.exit(1)
        else:
            print("\nâœ… Dataset validado com sucesso!")
            sys.exit(0)
            
    except Exception as e:
        print(f"âŒ Erro durante validaÃ§Ã£o: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 